|**实验报告**||
| :-: | - |
|**实验名称**||
|**实验人员**||**实验类型**|复现与分析报告|
|**实验目的**|<p>1. 了解并学习AD-NeRF模型的基本原理。</p><p>2. 复现AD-NeRF模型的数据预处理、模型训练、模型运行过程。</p><p>3. 针对AD-NeRF模型提出合理的改进意见。</p>|
|**仪器设备**|PC机（RTX 4060 + CUDA 12.0 + 8G显存）、PyCharm、GitHub|
||<p>一、 **实验内容**</p><p>- 基于参考资料，在GitHub平台上获取项目工程，并配置所需的第三方库文件。</p><p>- 提供环境所需的先决条件，安装PyTorch3D和下载所需的matlab工作环境文件。</p><p>- 执行项目训练过程，首先进行数据处理，获得训练过程中需要的Config.txt配置文件、json文件等。再训练模型，获得Loss值，PNSR值等，评估训练过程。</p><p>- 执行项目运行过程，重建原始视频与音频输入，并用另一个音频输入驱动目标人。</p><p>- 针对模型原理与复现过程，进行模型分析解读，并提出建议。</p><p>二、 **操作方法与实验步骤**</p><p>(1) 在GitHub下载该项目并导入到软件PyCharm中，搭建Anaconda平台，设置base环境运行位置为项目文件夹。</p><p>(2) 创建一个名称为adnerf的Anaconda虚拟环境并激活该环境，运行环境文件，快速配置第三方库文件。</p><p>(3) 使用Git克隆PyTorch3D，并根据设备适配的PyTorch、CUDA等库的版本，选择合适的PyTorch3D版本。</p><p>(4) 导入Basel Face Model 2019至3DMM文件夹下，保证PyTorch3D的正常运行。</p><p>(5) 在Shell中执行数据处理流程，获得模型训练所需的基本文件。</p><p>(6) 调用Python执行文件，训练Head-NeRF模型和Torso-NeRF模型。</p><p>(7) 调用Python执行文件，运行AD-NeRF模型进行渲染。</p><p>(8) 根据论文以及其他参考文献，提出模型改进意见。</p><p>三、 **复现实验数据记录和处理**</p><p>&emsp;3.1 <a name="ole_link2"></a>**预备阶段**</p><p>&emsp;&emsp;3.1.1 下载项目工程，导入PyCharm中，同时搭建Anaconda平台，设置base环境，运行代码conda env create -f environment.yml，快速配置第三方库文件，得到如<a name="ole_link1"></a>图3-1-1所示的异常信息。</p><p></p><img width="361" alt="image" src="https://github.com/Lweihan/Replication_of_AD-NeRF_Model/assets/100833228/ba25f39f-1d67-4b27-a534-195cab1e859f"><p>图3-1-1 虚拟环境创建异常报告</p><p>3.1.2 从图3-1-1可知，部分库文件无法使用conda下载，因此没有办法创建，这里考虑将这些报异常的库文件转至pip下载，发现异常消失，并开始生成虚拟环境adnerf，得到如图3-1-2的创建过程报告。</p><p></p><img width="361" alt="image" src="https://github.com/Lweihan/Replication_of_AD-NeRF_Model/assets/100833228/43e08cfe-fa0d-4226-beff-55c8770f72cd"><p>图3-1-2 第三方库文件下载过程</p><p>3.1.3 等待一段时间后，发现在/Anaconda/~/envs文件夹内创建了一个虚拟环境文件夹adnerf，如图3-1-3所示。</p><p></p><img width="361" alt="image" src="https://github.com/Lweihan/Replication_of_AD-NeRF_Model/assets/100833228/85e6d391-9b3f-4974-b475-b882ba942da2"><p>图3-1-3 adnerf虚拟环境创建结果</p><img width="361" alt="image" src="https://github.com/Lweihan/Replication_of_AD-NeRF_Model/assets/100833228/f96b7ec7-20d0-438a-9eec-6f80c4915e24"><p>3.1.4 接下来运行代码conda activate adnerf，激活虚拟环境。此时可以发现命令行上方出现（adnerf），说明库环境处于adnerf文件夹下。</p><p>&emsp;&emsp;3.1.5 在PC机上安装好Git后[2]，将Git和GitHub进行连接后，就可以从GitHub平台上直接传输文件夹至指定位置了。执行代码git clone <https://github.com/facebookresearch/pytorch3d.git，就可以将PyTorch3D文件夹克隆到本机项目文件夹下，如图3-1-4所示。>此外，为了实现跨境传输，需要配置代理接口，如图3-1-5所示。</p><p></p><p>图3-1-4 git克隆过程</p><p></p><img width="361" alt="image" src="https://github.com/Lweihan/Replication_of_AD-NeRF_Model/assets/100833228/c5dbae64-66d5-4388-81af-00e8dcb7b8bc"><p>图3-1-5 git代理配置</p><p>3.1.6 使用代码cd pytorch3d可以将当前工作位置转移到$id/pytorch3d文件夹中，再执行代码pip install -e .，可以使用pip进行下载，但是直接安装会出现如图3-1-6所示的异常。</p><p></p><img width="361" alt="image" src="https://github.com/Lweihan/Replication_of_AD-NeRF_Model/assets/100833228/3458b31b-bbc9-4d6a-8ea2-fc3966bfcc2d"><p>图3-1-6 pytorch3d安装异常</p><p>3.1.7 为了实现PyTorch3D的正常运行，需要了解项目中使用Pytorch和CUDATOOlKit的版本，使用代码conda list可以检查当前虚拟环境下的第三方库的信息，从中得知使用的是pytorch 1.12.0 + torchaudio 0.12.1 + torchvision 0.13.0 + cudatoolkit 11.6 + cudnn 8.0.5的组合。</p><p>&emsp;&emsp;3.1.8 为了检查上述的组合是否适配，可以在命令行中输入python，进入python环境，再依次运行import torch、torch.cuda.is\_available()确认组合是否适合，若打印出True，则代表适合。经验证，组合适配，如图3-1-7所示。</p><p></p><img width="361" alt="image" src="https://github.com/Lweihan/Replication_of_AD-NeRF_Model/assets/100833228/6bbdd825-0dc6-42bd-a529-746223b8a3aa"><p>图3-1-7 pytorch与cuda适配验证结果</p><p>3.1.9 命令行执行代码conda install -c fvcore -c iopath -c conda-forge fvcore iopath下载所需的基本配置。</p><p>&emsp;&emsp;3.1.10 在VS2019自带的终端x64 Native Tools Command Prompt for VS2019中在安装目录下执行代码set DISTUTILIS\_USE\_SDK=1和set PYTRCH3D\_NO\_NINJA=1。此外，还需要下CUB，并配置到环境变量中，命名为CUB\_HOME。至此，前提条件完全满足，可以执行3.1.6提到的代码，等待大约5分钟后显示安装成功，如图3-1-8所示。</p><p></p><img width="361" alt="image" src="https://github.com/Lweihan/Replication_of_AD-NeRF_Model/assets/100833228/04b007f8-7d79-45d6-b086-4dcd36cc08cd"><p>图3-1-8 pytorch3d安装结果</p><p>3.1.11 进入Base Face Model 2009官网中，如图3-1-8所示，进入下载页面后，提交姓名、机构和邮箱后申请到账号密码，下载模型文件压缩包。将其中的文件01\_MorphableModel.mat解压到项目文件夹/data\_util/face\_tracking/3DMM下，如图3-1-9所示。</p><p></p><img width="362" alt="image" src="https://github.com/Lweihan/Replication_of_AD-NeRF_Model/assets/100833228/0121bf0a-0b27-4c58-9031-5f685fca8267"><p>图3-1-8 Base Face Model官网</p><p></p><img width="361" alt="image" src="https://github.com/Lweihan/Replication_of_AD-NeRF_Model/assets/100833228/01b9c555-05e1-4324-a284-47b12e6fe930"><p>图3-1-9 脸部模型的放置</p><p>3.1.12 执行代码cd data\_util/face\_tracking，将工作环境转移至该目录下，运行convert\_BFM.py文件，至此先决条件均已满足。</p><p>&emsp;3.2 **训练阶段**</p><p>&emsp;&emsp;3.2.1 先需要执行数据处理文件process\_data.sh，因此需要shell环境，下载Git后，需要将bash.exe文件配置到PyCharm的shell路径，如图3-2-1所示。配置完成后，重新打开终端，可以发现处于shell环境，如图3-2-2所示。</p><p></p><img width="361" alt="image" src="https://github.com/Lweihan/Replication_of_AD-NeRF_Model/assets/100833228/58e42ebd-e412-449d-b2a0-3606bcc473ce"><p>图3-2-1 shell路径的设置</p><p></p><img width="361" alt="image" src="https://github.com/Lweihan/Replication_of_AD-NeRF_Model/assets/100833228/5e0e9e90-cc2b-4be6-a823-02c8365961b9"><p>图3-2-2 shell环境</p><p>3.2.2 在shell环境下，执行命令bash process\_data.sh Obama，即以Obama为输出文件夹，执行process\_data.sh文件。通过观察process\_data.sh文件可以发现，该文件主要分步骤执行了data\_util/process\_data.py文件。</p><p>&emsp;&emsp;3.2.3 执行上述指令后发生模型未发现异常，提示缺少cv2模型，如图3-2-3所示。通过查询得知，模型cv2的库名为opencv-python，因此使用指令pip install opencv-python装载所需的库，如图3-2-4所示。</p><p></p><img width="361" alt="image" src="https://github.com/Lweihan/Replication_of_AD-NeRF_Model/assets/100833228/91d74906-1ef2-45bb-b3e8-a9c238b1b131"><p>图3-2-3 process\_data-模型未发现异常（cv2）</p><p></p><img width="361" alt="image" src="https://github.com/Lweihan/Replication_of_AD-NeRF_Model/assets/100833228/f6a1b1e7-a56a-49bf-9f7a-f738ce665462"><p>图3-2-4 opencv-python库的安装</p><p>3.2.4 继续执行命令bash process\_data.sh Obama，再次发生模型未发现异常，如图3-2-5所示。通过查询得知，缺少库文件face\_alignment，因此使用指令pip install face\_alignment安装库文件，如图3-2-6所示。</p><p></p><img width="361" alt="image" src="https://github.com/Lweihan/Replication_of_AD-NeRF_Model/assets/100833228/800eb4fe-c511-4d52-b745-6348072705ae"><p>图3-2-5 process\_data-模型未发现异常（face\_alignment）</p><p></p><img width="361" alt="image" src="https://github.com/Lweihan/Replication_of_AD-NeRF_Model/assets/100833228/af6971b2-0c88-440e-ac9d-c94cf636b32d"><p>图3-2-6 face\_alignment库的安装</p><p>3.2.5 再次执行bash process\_data.sh Obama，发生如图3-2-5所示的异常警告。通过报告信息可知，当前操作要初始化libiomp5md.dll文件，但是发现该文件已经被初始化了。推测为之前虽然发生异常，但是仍执行了初始化任务。因此，考虑直接删除libiomp5md.dll文件，如图3-2-6所示，该文件位于/Anaconda/~/Library/bin路径下。同时，报告建议加上语句os.environ[‘KMP\_DUPLICATE\_OK’]=’True’，如图3-2-7所示，在报错处添加语句，以防止再次报错。</p><p></p><img width="361" alt="image" src="https://github.com/Lweihan/Replication_of_AD-NeRF_Model/assets/100833228/24916ad6-4bb2-49cb-8852-cec9692343f0"><p>图3-2-5 动态链接库调用异常</p><p></p><img width="361" alt="image" src="https://github.com/Lweihan/Replication_of_AD-NeRF_Model/assets/100833228/da66b5dc-51df-4834-a26a-46d3aa1824ae"><p>图3-2-6 libiomp5md.dll文件位置</p><p></p><img width="361" alt="image" src="https://github.com/Lweihan/Replication_of_AD-NeRF_Model/assets/100833228/a969d79d-6837-4c54-9d63-f2212b26a995"><p>图3-2-7 dll语句补充 </p><p>3.2.6 再次运行指令bash process\_data.sh Obama，发生异常。异常指出缺少逻辑值deepspeech/logits:0。首先推测缺少相关的库，因此使用git指令克隆deepspeech到该项目文件，如图3-2-8所示。</p><p></p><p>图3-2-8 deepspeech库文件的补充</p><p>3.2.7 经上述操作补充后，运行bash process\_data.Obama仍存在报错信息，因此前往报错处检查，发现出错函数为get\_tensor\_by\_name，推测出错原因与tensorflow有关，检查发现当前的tensorflow版本为2.3.0属于tensorflow2，而原项目的tensorflow版本为1.15.0属于tensorflow1。故此，可以确定是由于版本升级删除了相关的属性值，卸载当前的tensorflow2，按项目要求安装tensorflow 1.15.0，如图3-2-9所示。安装后，报错消失，问题解决。</p><p></p><p>图3-2-9 tensorflow库的降级</p><p>3.2.8 同时由于3.2.5添加语句后，base环境需要使用指令source activate唤醒，如图3-2-10所示。</p><p></p><p>图3-2-10 base环境的唤醒</p><p>3.2.9 再次运行bash process\_data.sh Obama，发生如图3-2-11异常。找到报错处，发现出错函数为FaceAlignment，推测第三方库face-alignment出现问题。使用指令conda list检查face-alignment发现版本为1.4，如图3-2-12所示。高于项目要求的1.3.4，所以卸载当前版本，安装1.3.4版本，如图3-2-13所示。</p><p></p><p>图3-2-11 FaceAlignemt函数异常</p><p></p><p>图3-2-12 当前的face-alignment库版本</p><p></p><p>图3-2-13 修改后的face-alignment库版本</p><p>3.2.10 再次运行后，上述问题解决，执行了step 0和step 1步骤，但是因为之前已经创建了Obama/aud.wav和Obama/aud.npy，因此本次运行时会询问是否重写文件，可以发现代码已经默认设置了不重写，如图3-2-14和图3-2-15所示。经过运行后，通过命令行窗口可以得知从https://www.adrianbulat.com/download下载文件夹。检查项目工程文件夹中，发现名为Obama的文件夹，如图3-2-16所示。</p><p></p><p>图3-2-14 step 1运行过程</p><p></p><p>图3-2-15 step 0运行过程</p><p></p><p>图3-2-16 新增的Obama文件夹</p><p>3.2.11 经过step 1后，可以发现在/dataset/Obama/ori\_imgs目录下，Obama的图像被提取出来，共含8000张图像，标志step 1成功完成，如图3-2-17所示。</p><p></p><p>图3-2-17 Obama图像提取结果</p><p></p><p>3.2.12 继续向下运行，报出警示，Audio有多通道，首位通道被使用，如图3-2-18所示，但是根据查询可以判断该警示不影响训练结果。可以继续向下进行step 2步骤，检测landmarks，如图3-2-19所示。</p><p></p><p>图3-2-18 通道警示</p><p></p><p>图3-2-19 step 2运行过程</p><p>3.2.13 经过step 2后，可以发现在/dataset/Obama/ori\_imgs目录下，每个图像被创建lms文件，共8000份，标志step 2成功完成，如图3-2-20所示。</p><p></p><p>图3-2-20 landmarks提取结果</p><p>3.2.14 继续向下运行，进入step3面部解析和step6头部姿态评估，程序每解析100张会打印当前处理数，每解析600张会弹出处理情况，如图3-2-21所示。</p><p></p><p>图3-2-21 step 3运行过程</p><p>3.2.15 经过step 3后，可以发现在/dataset/Obama/parsing目录下，每个图像被解析的结果图像，共8000张，标志step 3成功完成，如图3-2-22所示。</p><p></p><p>图3-2-22 图像解析结果</p><p>3.2.16 继续向下进行，进入step 4提取背景图像，该过程会展示部分提取信息，如图3-2-23所示。</p><p></p><p>图3-2-23 step 4运行过程</p><p>3.2.17 经过step 4后，可以发现在/dataset/Obama目录下，背景图像被提取出来，命名为bc.jpg，标志step 4成功完成，如图3-2-22所示。</p><p></p><p>图3-2-24 背景提取结果</p><p>3.2.18 继续向下进行，进入step 5保存训练图像，同时step 6被执行，该过程每完成1张都会打印当前完成结果，如图3-2-25所示。</p><p></p><p>图3-2-25 step 5运行过程</p><p>3.2.19 经过step 5后，可以发现在/dataset/Obama/head\_imgs以及/dataset/Obama/com\_imgs目录下，Obama图像的{头部与背景图像}和{背景与整个上半身图像}被分别提取出来，两个文件夹分别存储8000张，标志step 5成功完成，如图3-2-26和图3-2-27所示。</p><p></p><p>图3-2-26 {头部与背景图像}提取结果</p><p></p><p>图3-2-27 {背景与整个上半身图像}提取结果</p><p>3.2.20 经过step 6后，可以发现在/dataset/Obama目录下，生成了一个名叫debug的文件夹，在该文件夹下的debug\_render文件夹，生成了头部估计姿态图像，如图3-2-28所示。</p><p></p><p>图3-2-28 头部估计姿态生成结果</p><p>3.2.21 此外，经过经过2个半小时左右后，可以发现在dataset/Obama目录下，生成后续step 7所需的模型参数文件track\_params.pt，标志step 6成功完成，如图3-2-29所示。</p><p></p><p>图3-2-29 track\_params.pt文件生成结果</p><p>3.2.22 继续向下进行，进入step 7训练配置文件生成阶段，该过程会生成5个文件分别是HeadNeRF\_config.txt、TorsoNeRF\_config.txt、TorsoNeRFTest\_config.txt、transforms\_train.json、transforms\_val.json，如图3-2-30所示。</p><p></p><p>图3-2-30 step 7文件生成结果</p><p>3.2.23 经过step 7后，可以发现打印了Obama data processed done!，标志数据准备阶段完成，如图3-2-31所示。</p><p></p><p>图3-2-31 数据准备阶段的完成</p><p>3.2.24 执行命令python NeRFs/HeadNeRF/run\_nerf.py --config dataset/$id/HeadNeRF\_config.txt，发生异常如图3-2-32所示。</p><p></p><p>图3-2-32 Head-NeRF模型训练报错</p><p>3.2.25 经查询知该报错是由于Adam和AdamW优化器新引入的参数（可捕获）有关。分别执行语句：</p><p>pip install torch==1.12.1+cu116 torchvision==0.13.1+cu116 torchaudio==0.12.1 --extra-index-url <https://download.pytorch.org/whl/cu116></p><p>pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117</p><p>用以更新Pytorch版本，如图3-2-33所示。</p><p></p><p>图3-2-33 PyTorch的更新</p><p>3.2.26 此处为了便于展示和实验复现，修改了配置文件将训练次数从40000次修改至400次，该阶段每结果100次迭代，会打印当前损失值以及PSNR值，如图3-2-34所示。</p><p></p><p>图3-2-34 Head-NeRF模型的训练</p><p>3.2.27 经过上述过程可以发现在/dataset/Obama/logs下生成了两个文件夹，分别为Obama\_head和Obama\_com文件，在Obama\_head文件夹中存放这刚才训练的结果，如图3-2-35所示。</p><p></p><p>图3-2-35 Head-NeRF模型的训练结果</p><p>3.2.28 将Head-NeRF的训练结果复制到Obama\_com文件夹下，如图3-2-36所示。</p><p></p><p>图3-2-36 Head-NeRF模型训练结果的复制</p><p>3.2.29 执行指令python NeRFs/TorsoNeRF/run\_nerf.py --config dataset/$id/TorsoNeRF\_config.txt，训练Torso-NeRF模型，此处为了便于展示，将配置文件中的迭代总数设置成为了8，如图3-2-37所示。</p><p></p><p>图3-2-37 Torso-NeRF模型的训练</p><p>3.3 **运行阶段**</p><p>&emsp;&emsp;3.3.1 执行命令python NeRFs/TorsoNeRF/run\_nerf.py --config dataset/$id/TorsoNeRFTest\_config.txt --aud\_file=dataset/$id/aud.npy --test\_size=300，发生异常，如图3-3-1所示。</p><p></p><p>图3-3-1 重构异常</p><p>3.3.2 根据报告信息可知，未发现aud.npy文件。通过检查命令可知，需要将$id替换成设置的Obama，执行命令，如图3-3-2所示。</p><p></p><p><a name="ole_link3"></a>图3-3-2 执行重构</p><p>3.3.3 经过训练后可以发现在/dataset/Obama/logs/Obama\_com目录下，生成了一个文件夹为test\_and\_rst，标志着完成了重构任务，并得到了结果文件result，此处为了便于展示将上述的testsize设为18，得到如图3-3-3所示结果。此外将参数aud\_file替换成另一个.npy深度讲话特征文件，即可以实现用另一个音频输入驱动目标人，至此AD-NeRF项目复现完成。</p><p></p><p>图3-3-3 重构结果</p><p>四、 **实验结果分析与改进方案**</p><p>**4.1 实验结果分析**</p><p>AD-NeRF(Audio-driven Neural Radiance Field Model)，音频驱动的神经辐射场模型利用辐射场来避免在处理跨模态的映射问题中引入中间表示。得益于神经辐射场，可以对面部细节组件如牙齿、头发进行细致化地建模，其效果远优于传统的二维图像生成方法。</p><p>具体来看，该方法以视频序列，包括目标说话人的视频和音轨作为输入，基于DeepSpeech提取的音频特征，结合人脸解析的映射关系，建立一个音频条件的隐蔽式函数。此外，由于头部部分与头部以下的下半身的运动差异，进一步将NeRF分成两个部分进行渲染，一个是前景的脸，另一个是前景的躯干。通过这种方式，可以在收集到的训练数据中生成自然的说话头序列。</p><p>训练阶段每100次迭代都会打印当前PSNR值，可以发现Head-NeRF模型和Torso-NeRF模型初始约为26.85，随后逐渐提升，在6000次保持在38.5至42左右浮动。经过查询可知，峰值信噪比处于30-40表明失真较少，图像质量较高；处于40以上表明失真极少，图像质量十分趋于原图像。据此可以看出AD-NeRF在实验过程中，高质量地还原了Obama音频中的图像细节。</p><p>**4.2 改进方案**</p><p>尽管AD-NeRF模型在Obama.mp4音频重构实验中表现十分出色，但仍存在一些潜在的不足之处。AD-NeRF模型的训练阶段仍需要大量的数据和计算资源。由于训练源码大约需要使用12-14G的显存，本机的显存仅为8G，难以支持源码训练，因此采用修改解析参数default为8，batch\_size改为10。因此如何在保证性能的同时降低训练成本，是该模型优化的关键问题。</p><p>在复现过程中采用了直接修改参数的方式，虽然可以使得模型训练时间成本降低，但难免会对模型的精度产生影响，为了解决这一问题可以考虑以下两个方面：</p><p>- 轻量级网络结构：AD-NeRF模型采用了深度学习技术，其关键特征在于通过使用合适参数的轻量级网络可以有效地降低训练时间成本，并保持模型的高精度，如引入残差网络。</p><p>- 高效优化算法：AD-NeRF模型的优化器采用了Adam，初始学习率为0.0005。可以考虑使用高效的优化算法来提高寻找全局最优的过程，如考虑使用Sophia优化器。</p><p>此外，该模型的性能可能会受到物体结构复杂度和光影效果等条件的影响，提高模型细节处理能力和泛化能力也是改进目标的关键所在。根据以上问题，可以考虑以下两个方面：</p><p>- 引入高级的注意力机制：当前AD-NeRF模型的注意力机制可能不足以处理复杂场合下的细节信息，因此可以考虑引入高级注意力机制的方式提高处理能力，如Fastformer等。</p><p>- 扩展到多视角重建：AD-NeRF模型可以扩展到多视角重建中，从多个视角的图像中重建出三维场景。通过引入更多的图像数据，可以提高模型的重建精度与视觉效果。</p><p>五、 **讨论与心得**</p><p>在本次夏令营活动中，我实现了使用AD-NeRF模型重建Obama.mp4视频文件的实验复现。实验过程中，从对Anaconda虚拟环境的搭建、到检查报错以确定出错函数、到检查库文件版本、到检查具体变量、等操作，充分提高了我的debug能力与项目复现能力。此外，在安装PyTorch3D的过程中，我对GPU、CUDA、PyTorch、CUB之间的关系有了一个十分深刻的理解。同时，Visual Studio环境的搭建过程也是让我对C++环境的理解更进一步。Shell命令的使用也是本次复现实验的重要收获，充分地运用了Git下的bash.exe来调试代码。</p><p>首次接触NeRF模型让我感到十分激动，实验过程中在经过漫长的出错问题思考与试探后，成功解决问题、代码向下运行时都会带给我满满的收获感。在不停寻找问题的解决方案的过程中，了解到了许多有关硬件与软件搭配的相关知识，以及感知计算领域内的最新研究情况，激发了我对元宇宙与三维场景重建等领域的探索热情。</p>|

-第34页-





